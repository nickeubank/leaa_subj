{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1N4J9HGN3DDOPQL6Jsdf1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickeubank/leaa_subj/blob/main/leaa_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eTb6mpInkN0P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        ")\n",
        "\n",
        "pd.set_option(\"mode.copy_on_write\", True)\n",
        "\n",
        "dir = \"https://github.com/nickeubank/leaa_subj/raw/refs/heads/main/\"\n",
        "grants = pd.read_parquet(dir + \"subj_text_and_labels.parquet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "####\n",
        "# Google drive\n",
        "#####\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "dir = \"/content/gdrive/MyDrive/leaa/\"\n",
        "\n",
        "#########\n",
        "# Split into train test and for predict\n",
        "#########\n",
        "grants = grants.drop_duplicates(\"description\")\n",
        "unlabeled = grants[grants[\"label_1\"].isnull()]\n",
        "\n",
        "# Load Model and Tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained(dir + \"bert_grant_classifier\")\n",
        "tokenizer = BertTokenizer.from_pretrained(dir + \"bert_grant_classifier\")\n",
        "label_encoder = torch.load(dir + \"label_encoder.pth\", weights_only=False)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "290vQfowkwHw",
        "outputId": "4b0f2d7a-3de5-44eb-f632-553018efde2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "descriptions = list(grants[\"description\"].values)[0:100]\n",
        "\n",
        "all_predictions = []\n",
        "\n",
        "for i in range(0, len(descriptions), 16):\n",
        "  print(f\"starting batch {i}\")\n",
        "  batch = descriptions[i : i + 16]\n",
        "\n",
        "  inputs = tokenizer(\n",
        "      batch,\n",
        "      return_tensors=\"pt\",\n",
        "      padding=\"max_length\",\n",
        "      truncation=True,\n",
        "      max_length=128,\n",
        "  ).to(device)\n",
        "  outputs = model(**inputs)\n",
        "  predicted_classes = torch.argmax(outputs.logits, dim=1)\n",
        "  batch_predictions = label_encoder.inverse_transform(predicted_classes.cpu().numpy())\n",
        "  all_predictions.extend(batch_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_4mgU8Ek7Ol",
        "outputId": "d13ca00f-5859-4322-d621-473e1b4a50e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting batch 0\n",
            "starting batch 16\n",
            "starting batch 32\n",
            "starting batch 48\n",
            "starting batch 64\n",
            "starting batch 80\n",
            "starting batch 96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the predicted labels to the 'unlabeled' DataFrame\n",
        "unlabeled[\"predicted_label\"] = all_predictions\n",
        "\n",
        "print(unlabeled[[\"description\", \"predicted_label\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "3p-Fsyh7pVr_",
        "outputId": "0c6a7de4-a57d-4651-e125-8b3c5a6a09c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'predicted_label'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'predicted_label'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5ad476189a61>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add the predicted labels to the 'unlabeled' DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0munlabeled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predicted_label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munlabeled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"description\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predicted_label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'predicted_label'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCpHL-wgqJmw",
        "outputId": "056c261e-1c6d-45bb-d3ff-27f7867c05c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0),\n",
              " np.float64(2.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unlabeled.to_parquet(dir + \"predicted_labels_1digit.parquet\")"
      ],
      "metadata": {
        "id": "rgKKGNWun0CP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7VPp3h3VnxBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "A3ugwVS6l5L-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}