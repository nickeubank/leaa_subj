{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickeubank/leaa_subj/blob/main/leaa_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eTb6mpInkN0P"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/hpc/group/ssri/nce8/miniforge3/envs/torch/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        ")\n",
        "\n",
        "pd.set_option(\"mode.copy_on_write\", True)\n",
        "\n",
        "repo_id = \"nickeubank/leaa_grant_subjects_invweighted\"\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "\n",
        "grants = pd.read_parquet(\"../00_source_data/subj_text_and_labels.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#########\n",
        "# Split into train test and for predict\n",
        "#########\n",
        "grants = grants.drop_duplicates(\"description\")\n",
        "grants[\"label_1_encoded\"] = grants[\"label_1\"] - 1\n",
        "\n",
        "# Load Model and Tokenizer\n",
        "assert torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(repo_id).to(device)\n",
        "tokenizer = BertTokenizer.from_pretrained(repo_id)\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_4mgU8Ek7Ol",
        "outputId": "d13ca00f-5859-4322-d621-473e1b4a50e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting batch 0\n",
            "starting batch 10000\n",
            "starting batch 20000\n",
            "starting batch 30000\n",
            "starting batch 40000\n",
            "starting batch 50000\n",
            "starting batch 60000\n",
            "starting batch 70000\n",
            "starting batch 80000\n",
            "starting batch 90000\n",
            "starting batch 100000\n",
            "starting batch 110000\n",
            "starting batch 120000\n",
            "starting batch 130000\n",
            "starting batch 140000\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "descriptions = list(grants[\"description\"].values)\n",
        "\n",
        "all_predictions = []\n",
        "\n",
        "for i in range(0, len(descriptions), BATCH_SIZE):\n",
        "    if i % 10_000 == 0:\n",
        "        print(f\"starting batch {i}\")\n",
        "\n",
        "    batch = descriptions[i : i + BATCH_SIZE]\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        batch,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=MAX_LEN,\n",
        "    ).to(device)\n",
        "\n",
        "    outputs = model(**inputs)\n",
        "    predicted_classes = torch.argmax(outputs.logits, dim=1)\n",
        "    formatted_to_list = list(map(lambda x: x.item(), predicted_classes))\n",
        "    all_predictions.extend(formatted_to_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "143664"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "3p-Fsyh7pVr_",
        "outputId": "0c6a7de4-a57d-4651-e125-8b3c5a6a09c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                         description  predicted_label_1  \\\n",
            "0  Title: COMMUNICATIONS EQUIP.\\nDescription: NO ...                  2   \n",
            "1  Title: EQUIP.\\nDescription: THE NEWLY CREATED ...                  4   \n",
            "2  Title: NARCO EFFECTIVENESS\\nDescription: SUMMA...                  1   \n",
            "3  Title: ADVANCED TRAINING OF POLYGRAPH EXAMINER...                  2   \n",
            "4  Title: RIOT CONTROL EQUIP.\\nDescription: NO PR...                  4   \n",
            "\n",
            "   label_1  label_2  \n",
            "0      NaN      NaN  \n",
            "1      NaN      NaN  \n",
            "2      NaN      NaN  \n",
            "3      NaN      NaN  \n",
            "4      NaN      NaN  \n"
          ]
        }
      ],
      "source": [
        "# Add the predicted labels to the 'unlabeled' DataFrame\n",
        "grants[\"predicted_label_1\"] = all_predictions\n",
        "grants[\"predicted_label_1\"] += 1  # fix \"encoding\"\n",
        "print(grants[[\"description\", \"predicted_label_1\", \"label_1\", \"label_2\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert (\n",
        "    grants.loc[grants[\"label_1\"].notnull(), \"predicted_label_1\"]\n",
        "    == grants.loc[grants[\"label_1\"].notnull(), \"label_1\"]\n",
        ").mean() > 0.95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rgKKGNWun0CP"
      },
      "outputs": [],
      "source": [
        "grants[[\"description\", \"predicted_label_1\", \"label_1\", \"label_2\"]].to_parquet(\n",
        "    \"../20_intermediate_data/predicted_labels_1digit_weighted.parquet\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM1N4J9HGN3DDOPQL6Jsdf1",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
